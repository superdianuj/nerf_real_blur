cp: -r not specified; omitting directory 'scene/images/blurbasket_deblurred_nafnet_deblurred_esrgan'
/home/kan/anaconda3/envs/torcher/lib/python3.8/site-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)
  _C._set_default_tensor_type(t)
Minifying 1 scene
Traceback (most recent call last):
  File "run_nerf.py", line 757, in <module>
    train()
  File "run_nerf.py", line 259, in train
    images, poses, bds, render_poses, i_test = load_llff_data(args, args.datadir, args.factor,
  File "/home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/load_llff.py", line 242, in load_llff_data
    poses, bds, imgs = _load_data(basedir, factor=factor)  # factor=8 downsamples original imgs by 8x
  File "/home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/load_llff.py", line 73, in _load_data
    _minify(basedir, factors=[factor])
  File "/home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/load_llff.py", line 45, in _minify
    check_output('cp {}/* {}'.format(imgdir_orig, imgdir), shell=True)
  File "/home/kan/anaconda3/envs/torcher/lib/python3.8/subprocess.py", line 415, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
  File "/home/kan/anaconda3/envs/torcher/lib/python3.8/subprocess.py", line 516, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cp scene/images/* scene/images_1' returned non-zero exit status 1.
OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
```============================================='''
  SSIM :    0.6318599
  PSNR :   30.5413833
  LPIPS:    0.3477666
```============================================='''


OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Loaded image data (1600, 2400, 3, 42) [1600.         2400.         1672.50629047]
Loaded scene 13.412435130405875 276.90216496616404
recentered (3, 5)
[[ 1.0000000e+00  1.8484084e-10 -1.0183368e-08  3.5478956e-10]
 [-1.8484085e-10  1.0000000e+00 -1.6079003e-09 -1.0998476e-08]
 [ 1.0183368e-08  1.6079003e-09  1.0000000e+00 -3.1931060e-09]]
Data:
(42, 3, 5) (42, 1600, 2400, 3) (42, 2)
HOLDOUT view is 14
Loaded llff (42, 1600, 2400, 3) (120, 3, 5) [1600.     2400.     1672.5063] scene
LLFF holdout, 2
DEFINING BOUNDS
NEAR FAR 0.0 1.0
Found ckpts []
train on image sequence of len = 42, 2400x1600
get rays
shuffle rays
done
Begin
TRAIN views are [ 1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41]
TEST views are [ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]
VAL views are [ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]
0 0.00010704994201660156
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 87.03977990150452
2 87.06495261192322
3 86.92725658416748
4 86.87859654426575
5 86.91586971282959
6 87.59073233604431
7 86.99996972084045
8 178.19043564796448
9 204.6772403717041
10 205.10092997550964
11 204.65421533584595
12 205.17148399353027
13 190.4595959186554
14 182.65853834152222
15 183.11006426811218
16 183.22670793533325
17 183.3598873615265
18 182.6474220752716
19 195.16793060302734
20 251.9955985546112
21 260.1063311100006
22 239.21525144577026
23 242.22709274291992
24 241.36600804328918
25 254.198237657547
26 235.39126992225647
27 239.51351284980774
28 240.2101812362671
29 241.98605751991272
30 243.0629780292511
31 232.50973558425903
32 233.97575330734253
33 244.0207004547119
34 243.77867484092712
35 237.1429796218872
36 237.61843943595886
37 238.80258059501648
38 238.79231429100037
39 238.43368911743164
40 239.79505968093872
41 238.30975890159607
42 235.658344745636
43 236.0779163837433
44 236.5728199481964
45 236.86576867103577
46 120.99708557128906
47 87.07853507995605
48 87.07364296913147
49 87.10984706878662
50 87.07055854797363
51 87.08015036582947
52 87.15206241607666
53 87.14271926879883
54 87.10153460502625
55 87.11300158500671
56 87.16124367713928
57 87.16218781471252
58 87.07770204544067
59 87.21335554122925
60 87.07377529144287
61 87.1456081867218
62 87.09037852287292
63 87.15363335609436
64 87.1077573299408
65 87.116868019104
66 87.10654973983765
67 87.12319850921631
68 87.09988331794739
69 87.06424975395203
70 87.10976505279541
71 87.1397795677185
72 87.10607814788818
73 87.12984871864319
74 87.1608362197876
75 87.13964104652405
76 87.15759325027466
77 87.17177724838257
78 87.17711472511292
79 87.18966937065125
80 87.21365427970886
81 87.17914724349976
82 87.23297262191772
83 87.17049431800842
84 87.18229103088379
85 87.14781737327576
86 87.13266324996948
87 87.22231078147888
88 87.15802717208862
89 87.25628018379211
90 87.16349220275879
91 87.22304940223694
92 87.2166600227356
93 87.18686962127686
94 87.23819851875305
95 87.18883538246155
96 87.0960021018982
97 87.06965351104736
98 87.07958459854126
99 87.05111694335938
100 87.08875489234924
101 87.02282500267029
102 87.07820510864258
103 87.06607174873352
104 87.06430840492249
105 87.08661723136902
106 87.01118063926697
107 87.05239248275757
108 87.00011372566223
109 87.05360174179077
110 87.04700350761414
111 87.02735447883606
112 87.01282215118408
113 86.98020958900452
114 86.99654722213745
115 86.96535062789917
116 86.9721040725708
117 86.9409921169281
118 87.0096526145935
119 87.03100967407227
Done, saving torch.Size([120, 1600, 2400, 3]) torch.Size([120, 1600, 2400])
(120, 1600, 2400, 3)
float32
1.0
0.0
(120, 1600, 2400)
float32
1.0
0.29525754
+++++++++++++++++++
----FUCK-----
test poses shape torch.Size([42, 3, 4])
Append 0 # of poses to fill all the GPUs
0 8.177757263183594e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 86.94816255569458
2 87.00706028938293
3 87.11107730865479
4 87.02239727973938
5 87.06158399581909
6 87.0840368270874
7 87.0447325706482
8 87.02296900749207
9 87.07175135612488
10 87.10455369949341
11 87.13095045089722
12 87.15778994560242
13 87.12480354309082
14 87.114741563797
15 86.99893951416016
16 87.00144362449646
17 86.99516034126282
18 87.00482082366943
19 87.022296667099
20 87.0454375743866
21 87.01629114151001
22 87.07823586463928
23 87.08806705474854
24 87.04160952568054
25 87.04165196418762
26 87.11479496955872
27 87.05299925804138
28 87.07882499694824
29 87.11276316642761
30 87.09329414367676
31 87.052987575531
32 87.06494092941284
33 87.01808142662048
34 86.98684215545654
35 87.0059084892273
36 87.01295733451843
37 87.0628936290741
38 87.09865975379944
39 87.11651468276978
40 87.1404778957367
41 87.14689922332764
Saved checkpoints at results/scene/020000.tar
0 8.678436279296875e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 86.99223327636719
2 86.98241639137268
3 87.00854110717773
4 87.00752878189087
5 86.99762868881226
6 86.9958770275116
7 87.03466010093689
8 87.03089022636414
9 87.01466608047485
10 87.00256776809692
11 86.98832273483276
12 86.99195194244385
13 87.01797533035278
14 87.01412963867188
15 87.01386523246765
16 87.00306463241577
17 87.01138520240784
18 87.02812600135803
19 87.01862120628357
20 87.04231142997742
21 87.00402879714966
22 87.0060248374939
23 86.99107766151428
24 87.02764868736267
25 87.00810551643372
26 87.01804542541504
27 86.99564671516418
28 86.98809289932251
29 86.97123265266418
30 86.97890973091125
31 86.96871519088745
32 86.98886370658875
33 86.98505568504333
34 87.00610899925232
35 87.01711630821228
36 87.02192187309265
37 87.04704999923706
38 87.03564500808716
39 87.02278208732605
40 87.01991271972656
41 87.00744104385376
42 86.97921895980835
43 86.9674460887909
44 86.96008777618408
45 86.92760109901428
46 86.92744183540344
47 86.90409827232361
48 86.90419578552246
49 86.91707277297974
50 86.90650153160095
51 86.90938115119934
52 86.89770078659058
53 86.89755821228027
54 86.88388085365295
55 86.86787629127502
56 86.87387418746948
57 86.85860705375671
58 86.86259579658508
59 86.83586120605469
60 86.88348388671875
61 86.8194031715393
62 86.8368558883667
63 86.84084582328796
64 86.83360934257507
65 86.83641314506531
66 86.8345742225647
67 86.85818004608154
68 86.91307473182678
69 86.86411738395691
70 86.86309742927551
71 86.86862993240356
72 86.85060453414917
73 86.79590201377869
74 86.84181046485901
75 86.835453748703
76 86.87942337989807
77 86.85849022865295
78 86.88789176940918
79 86.88263773918152
80 86.872567653656
81 86.92506408691406
82 86.92257881164551
83 86.83277106285095
84 86.89647769927979
85 86.88416695594788
86 86.8955295085907
87 86.90713930130005
88 86.90384030342102
89 86.88965177536011
90 86.90052151679993
91 86.8865954875946
92 86.86964702606201
93 86.90618824958801
94 86.88011407852173
95 86.89430952072144
96 86.88478636741638
97 86.84320950508118
98 86.89679861068726
99 86.86549520492554
100 86.87280011177063
101 86.8219211101532
102 86.9034035205841
103 86.88605046272278
104 86.86300563812256
105 86.907053232193
106 86.86742305755615
107 86.83851623535156
108 86.87232398986816
109 86.84071183204651
110 86.8701798915863
111 86.923983335495
112 86.89815473556519
113 86.84148979187012
114 86.88809728622437
115 86.90319395065308
116 86.87074542045593
117 86.85703682899475
118 86.91075873374939
119 86.8833544254303
Done, saving torch.Size([120, 1600, 2400, 3]) torch.Size([120, 1600, 2400])
(120, 1600, 2400, 3)
float32
1.0
0.0
(120, 1600, 2400)
float32
0.9999724
0.31133527
+++++++++++++++++++
----FUCK-----
test poses shape torch.Size([42, 3, 4])
Append 0 # of poses to fill all the GPUs
0 9.870529174804688e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 86.8100197315216
2 86.9493134021759
3 86.97342324256897
4 86.97210001945496
5 86.9738757610321
6 86.93644666671753
7 86.95630693435669
8 86.92892217636108
9 86.93340706825256
10 86.94933319091797
11 86.95933175086975
12 86.97365999221802
13 86.94383716583252
14 86.97361755371094
15 86.93951463699341
16 86.9168689250946
17 86.95496940612793
18 86.96912479400635
19 86.96229767799377
20 86.955641746521
21 86.93521761894226
22 86.91253614425659
23 86.95045399665833
24 86.93801808357239
25 86.96502494812012
26 86.98548316955566
27 86.93719244003296
28 86.969881772995Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
```============================================='''
  SSIM :    0.6513722
  PSNR :   30.8621818
  LPIPS:    0.3036508
```============================================='''


OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
```============================================='''
  SSIM :    0.6611587
  PSNR :   31.0124310
  LPIPS:    0.2786291
```============================================='''


OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
```============================================='''
  SSIM :    0.6698200
  PSNR :   31.0936859
  LPIPS:    0.2614648
```============================================='''



29 86.99904680252075
30 86.95959734916687
31 86.92063856124878
32 86.96353530883789
33 86.96632504463196
34 86.8912365436554
35 86.95825004577637
36 86.95377373695374
37 86.975745677948
38 86.96698641777039
39 86.93498992919922
40 86.95699501037598
41 86.93021297454834
0 0.000102996826171875
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 86.85126376152039
2 86.89958953857422
3 86.95723605155945
4 86.92521095275879
5 86.93845725059509
6 86.94108247756958
7 86.97143936157227
8 86.95147752761841
9 86.89919447898865
10 86.88979816436768
11 86.89935374259949
12 86.88263773918152
13 86.87110829353333
14 86.87820553779602
15 86.85766100883484
16 86.87645387649536
17 86.87325167655945
18 86.87607645988464
19 86.88054347038269
20 86.86193418502808
21 86.8708074092865
22 86.89162755012512
23 86.88050127029419
24 86.89307236671448
25 86.89765906333923
26 86.90954256057739
27 86.9044029712677
28 86.92048859596252
29 86.88961148262024
30 86.88937616348267
31 86.88431215286255
32 86.91648459434509
33 86.93083024024963
34 86.92535781860352
35 87.05832052230835
36 87.1514208316803
37 87.16314005851746
38 87.14452242851257
39 87.19258785247803
40 87.18171858787537
41 87.21493196487427
42 87.20791840553284
43 87.21386432647705
44 87.23187804222107
45 87.2283787727356
46 87.16815280914307
47 87.15430045127869
48 87.15779113769531
49 87.17069149017334
50 87.16869616508484
51 87.16750311851501
52 87.17535638809204
53 87.21926283836365
54 87.224680185318
55 87.21886229515076
56 87.22553539276123
57 87.22852826118469
58 87.23234415054321
59 87.24351167678833
60 87.25196123123169
61 87.21286368370056
62 87.25769829750061
63 87.23882055282593
64 87.24178314208984
65 87.24525904655457
66 87.2003345489502
67 87.24793720245361
68 87.16576886177063
69 87.20903468132019
70 87.21274733543396
71 87.20698475837708
72 87.20688128471375
73 87.22117400169373
74 87.23492383956909
75 87.18423175811768
76 87.24064993858337
77 87.20462155342102
78 87.25537967681885
79 87.21523451805115
80 87.24513554573059
81 87.19733548164368
82 87.25621294975281
83 87.21267771720886
84 87.26907539367676
85 87.21822738647461
86 87.22474575042725
87 87.26858353614807
88 87.22170114517212
89 87.19983863830566
90 87.22285795211792
91 87.25190043449402
92 87.23050379753113
93 87.2496747970581
94 87.28826689720154
95 87.27173328399658
96 87.30579590797424
97 87.34513568878174
98 87.29009675979614
99 87.353684425354
100 87.27434301376343
101 87.31564116477966
102 87.31312823295593
103 87.30730080604553
104 87.33163213729858
105 87.3466124534607
106 87.32905960083008
107 87.31993341445923
108 87.36524772644043
109 87.36521601676941
110 87.23172807693481
111 87.28803086280823
112 87.30667400360107
113 87.30903434753418
114 87.29508399963379
115 87.33223628997803
116 87.3271701335907
117 87.2810435295105
118 87.31850481033325
119 87.35733127593994
Done, saving torch.Size([120, 1600, 2400, 3]) torch.Size([120, 1600, 2400])
(120, 1600, 2400, 3)
float32
1.0
0.0
(120, 1600, 2400)
float32
0.9961899
0.36235508
+++++++++++++++++++
----FUCK-----
test poses shape torch.Size([42, 3, 4])
Append 0 # of poses to fill all the GPUs
0 8.0108642578125e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 87.27659487724304
2 87.31457304954529
3 87.41083550453186
4 87.34730458259583
5 87.3754153251648
6 87.37900733947754
7 87.39965724945068
8 87.34805011749268
9 87.33415341377258
10 87.36345314979553
11 87.40535831451416
12 87.414621591568
13 87.41389584541321
14 87.4202344417572
15 87.3529486656189
16 87.37036991119385
17 87.40519618988037
18 87.45550203323364
19 87.41944408416748
20 87.37434959411621
21 87.34426951408386
22 87.35125088691711
23 87.35935235023499
24 87.39852690696716
25 87.39808487892151
26 87.4399950504303
27 87.35685086250305
28 87.40991401672363
29 87.38754057884216
30 87.39039540290833
31 87.3572690486908
32 87.41170239448547
33 87.38962316513062
34 87.31576299667358
35 87.39264106750488
36 87.39931774139404
37 87.4454619884491
38 87.43452215194702
39 87.42991828918457
40 87.43856692314148
41 87.41011333465576
Saved checkpoints at results/scene/040000.tar
0 9.608268737792969e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 87.25757312774658
2 87.35286688804626
3 87.34370565414429
4 87.34898519515991
5 87.36188983917236
6 87.33487200737
7 87.38057374954224
8 87.3823630809784
9 87.41853976249695
10 87.40790510177612
11 87.40775871276855
12 87.41332006454468
13 87.4174280166626
14 87.39999890327454
15 87.41248846054077
16 87.40202903747559
17 87.41111040115356
18 87.41928219795227
19 87.42379117012024
20 87.41982412338257
21 87.4278359413147
22 87.42731404304504
23 87.44201040267944
24 87.44950127601624
25 87.43385648727417
26 87.42098760604858
27 87.44205927848816
28 87.40931582450867
29 87.42532205581665
30 87.39868593215942
31 87.42082357406616
32 87.4160361289978
33 87.41031885147095
34 87.42230176925659
35 87.42646074295044
36 87.4434814453125
37 87.47066044807434
38 87.44752836227417
39 87.4558253288269
40 87.43917322158813
41 87.46283149719238
42 87.4594497680664
43 87.46391081809998
44 87.45323586463928
45 87.46608662605286
46 87.4448823928833
47 87.4965546131134
48 87.52408647537231
49 87.4654803276062
50 87.48721528053284
51 87.49380993843079
52 87.48944234848022
53 87.49093437194824
54 87.50123119354248
55 87.49249148368835
56 87.48828530311584
57 87.49657893180847
58 87.47842335700989
59 87.43289232254028
60 87.4037344455719
61 87.38574147224426
62 87.41238451004028
63 87.43498015403748
64 87.41559624671936
65 87.45775079727173
66 87.41646003723145
67 87.48801040649414
68 87.49846148490906
69 87.51921820640564
70 87.48373627662659
71 87.5443959236145
72 87.52080798149109
73 87.49786472320557
74 87.46450614929199
75 87.44079566001892
76 87.4676501750946
77 87.42585039138794
78 87.49472117424011
79 87.47771430015564
80 87.48500752449036
81 87.46021437644958
82 87.47907876968384
83 87.45212006568909
84 87.48272681236267
85 87.48234963417053
86 87.30087351799011
87 87.45454168319702
88 87.49264931678772
89 87.43908095359802
90 87.43037724494934
91 87.4030511379242
92 87.44073414802551
93 87.50123977661133
94 87.52587819099426
95 87.37180399894714
96 87.41760802268982
97 87.45669388771057
98 87.45265603065491
99 87.43415951728821
100 87.47909569740295
101 87.44905233383179
102 87.45911979675293
103 87.4463472366333
104 87.46878433227539
105 87.4819164276123
106 87.5141031742096
107 87.36269974708557
108 87.48549842834473
109 87.46422719955444
110 87.48966240882874
111 87.51992106437683
112 87.49151515960693
113 87.37297940254211
114 87.4916718006134
115 87.52713012695312
116 87.46394491195679
117 87.52070879936218
118 87.46503353118896
119 87.53637218475342
Done, saving torch.Size([120, 1600, 2400, 3]) torch.Size([120, 1600, 2400])
(120, 1600, 2400, 3)
float32
1.0
0.0
(120, 1600, 2400)
float32
0.9975964
0.34565616
+++++++++++++++++++
----FUCK-----
test poses shape torch.Size([42, 3, 4])
Append 0 # of poses to fill all the GPUs
0 8.130073547363281e-05
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 87.35020589828491
2 87.45887112617493
3 87.4875373840332
4 87.47068452835083
5 87.49421191215515
6 87.46221780776978
7 87.47258830070496
8 87.45712876319885
9 87.48361587524414
10 87.49487590789795
11 87.53387999534607
12 87.51649165153503
13 87.51235103607178
14 87.5084331035614
15 87.43989610671997
16 87.4606773853302
17 87.50338006019592
18 87.5181872844696
19 87.51089787483215
20 87.51537156105042
21 87.49423861503601
22 87.48409271240234
23 87.5256838798523
24 87.5176305770874
25 87.55547642707825
26 87.55332374572754
27 87.47947835922241
28 87.47404742240906
29 87.5306887626648
30 87.51811671257019
31 87.44680166244507
32 87.50772190093994
33 87.47295451164246
34 87.45544838905334
35 87.4911687374115
36 87.51379895210266
37 87.55035305023193
38 87.53142476081848
39 87.53557443618774
40 87.53139233589172
41 87.53322267532349
0 0.00010251998901367188
torch.Size([1600, 2400, 3]) torch.Size([1600, 2400])
1 87.33283686637878
2 87.42103672027588
3 87.44422793388367
4 87.46173405647278
5 87.4525978565216
6 87.51447701454163
7 87.45794034004211
8 87.48168969154358
9 87.44627714157104
10 87.49503540992737
11 87.5615177154541
12 87.51348376274109
13 87.5089910030365
14 OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/kan/codework/gay_nerf_exps/NAFNet_Real-ESRGAN_nerf_blurbasket/Original-NeRF_nafnet_realesrgan/lpips/weights/v0.1/vgg.pth
```============================================='''
  SSIM :    0.6742266
  PSNR :   31.0722250
  LPIPS:    0.2497431
```============================================='''


